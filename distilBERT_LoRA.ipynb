{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)\n",
    "\n",
    "In this lecture, we will explore the architecture of DistilBERT, its key components, and how it can be utilized for various natural language processing tasks. Additionally, we'll discuss its advantages, limitations, and provide hands-on examples to showcase its effectiveness.\n",
    "\n",
    "Reference : [The Theory](https://towardsdatascience.com/distillation-of-bert-like-models-the-code-73c31e8c2b0a) | [Code](https://towardsdatascience.com/distillation-of-bert-like-models-the-theory-32e19a02641f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# # Set GPU device\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ekkar\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\Ekkar\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('3.2.0', '4.46.0', '2.1.1')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install datasets --upgrade\n",
    "import datasets\n",
    "import transformers\n",
    "import torch\n",
    "datasets.__version__, transformers.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import random, math, time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading our MNLI part of the GLUE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'comment_text', 'label'],\n",
       "        num_rows: 127656\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'comment_text', 'label'],\n",
       "        num_rows: 31915\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'comment_text', 'label'],\n",
       "        num_rows: 63978\n",
       "    })\n",
       "    balanced_train: Dataset({\n",
       "        features: ['id', 'comment_text', 'label'],\n",
       "        num_rows: 25868\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "###1. Load Dataset\n",
    "# task_to_keys = {\n",
    "#     \"cola\": (\"sentence\", None),\n",
    "#     \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "#     \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "#     \"qnli\": (\"question\", \"sentence\"),\n",
    "#     \"qqp\": (\"question1\", \"question2\"),\n",
    "#     \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "#     \"sst2\": (\"sentence\", None),\n",
    "#     \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "#     \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "# }\n",
    "\n",
    "# task_name = \"mnli\"\n",
    "# raw_datasets = datasets.load_dataset(\"glue\", task_name)\n",
    "# raw_datasets\n",
    "\n",
    "raw_datasets = datasets.load_dataset(\"OxAISH-AL-LLM/wiki_toxic\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '794c30aff0931384',\n",
       " 'comment_text': \"And that's not a personal attack^^ ?\",\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'non': 0, 'tox': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = raw_datasets['train'].features['label'].names\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'non', 1: 'tox'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: v for v, i in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "num_labels = np.unique(raw_datasets['train']['label']).size\n",
    "num_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"figures/BERT_embed.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "teacher_id = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
    "\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher_id, \n",
    "    num_labels = num_labels,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    ")\n",
    "\n",
    "teacher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(1): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(2): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(3): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(4): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(5): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(6): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(7): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(8): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(9): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(10): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "(11): BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSdpaSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(teacher_model.bert.encoder.layer):\n",
    "    print(f\"({i}): {layer}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_function(examples):\n",
    "#     sentence1_key, sentence2_key = task_to_keys[task_name]\n",
    "#     args = (\n",
    "#         (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "#     )\n",
    "#     result = tokenizer(*args, max_length=128, truncation=True)\n",
    "#     return result\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"comment_text\"], padding=\"max_length\", truncation=True, max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e01f622e5194a26af4fa43417949b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31915 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'comment_text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 127656\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'comment_text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 31915\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'comment_text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 63978\n",
       "    })\n",
       "    balanced_train: Dataset({\n",
       "        features: ['id', 'comment_text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25868\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list(task_to_keys[task_name])\n",
    "# column_dataset = [item for item in task_to_keys[task_name] if item is not None]\n",
    "# column_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #remove column : 'premise', 'hypothesis', 'idx'\n",
    "# tokenized_datasets = tokenized_datasets.remove_columns(column_dataset + [\"idx\"])\n",
    "# #rename column : 'labels'\n",
    "# tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "# tokenized_datasets.set_format(\"torch\")\n",
    "# tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 127656\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 31915\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 63978\n",
       "    })\n",
       "    balanced_train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25868\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"id\", \"comment_text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 1998, 2008, 1005, 1055, 2025, 1037, 3167, 2886, 1034, 1034, 1029,\n",
       "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] and that ' s not a personal attack ^ ^? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_datasets['train'][0]['input_ids'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "#Data collator that will dynamically pad the inputs received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=1150).select(range(2000))\n",
    "small_eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=1150).select(range(500))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=1150).select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    small_train_dataset, shuffle=True, batch_size=16, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(\n",
    "    small_test_dataset, batch_size=16, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(\n",
    "    small_eval_dataset, batch_size=16, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16]), torch.Size([16, 64]), torch.Size([16, 64]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "    \n",
    "batch['labels'].shape, batch['input_ids'].shape, batch['attention_mask'].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model and losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Teacher Model & Student Model\n",
    "\n",
    "####  Architecture \n",
    "In the present work, the student - DistilBERT - has the same general architecture as BERT. \n",
    "- The `token-type embeddings` and the `pooler` are removed while `the number of layers` is reduced by a factor of 2. \n",
    "- Most of the operations used in the Transformer architecture `linear layer` and `layer normalisation` are highly optimized in modern linear algebra frameworks.\n",
    "- our investigations showed that variations on the last dimension of the tensor (hidden size dimension) have a smaller impact on computation efficiency (for a fixed parameters budget) than variations on other factors like the number of layers. \n",
    "- Thus we focus on reducing the number of layers.\n",
    "\n",
    "#### Initialize Student Model\n",
    "- To initialize a new model from an existing one, we need to access the weights of the old model (the teacher). \n",
    "- In order to get the weights, we first have to know how to access them. Weâ€™ll use BERT as our teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"non\",\n",
       "    \"1\": \"tox\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"non\": 0,\n",
       "    \"tox\": 1\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.46.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model.config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "- The student model has the same configuration, except the number of layers is reduced by a factor of 2\n",
    "- The student layers are initilized by copying one out of two layers of the teacher, starting with layer 0.\n",
    "- The head of the teacher is also copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertConfig\n",
    "# Get teacher configuration as a dictionnary\n",
    "configuration = teacher_model.config.to_dict()\n",
    "# configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half the number of hidden layer\n",
    "configuration['num_hidden_layers'] //= 1\n",
    "# Convert the dictionnary to the student configuration\n",
    "configuration = BertConfig.from_dict(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create uninitialized student model\n",
    "model = type(teacher_model)(configuration)\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recursively copies the weights of the (teacher) to the (student).\n",
    "- This function is meant to be first called on a BertFor... model, but is then called on every children of that model recursively.\n",
    "- The only part that's not fully copied is the encoder, of which only half is copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertEncoder, BertModel\n",
    "from torch.nn import Module\n",
    "\n",
    "def distill_bert_weights(\n",
    "    teacher : Module,\n",
    "    student : Module,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Recursively copies the weights of the (teacher) to the (student).\n",
    "    This function is meant to be first called on a BertFor... model, but is then called on every children of that model recursively.\n",
    "    The only part that's not fully copied is the encoder, of which only half is copied.\n",
    "    \"\"\"\n",
    "    # If the part is an entire BERT model or a BERTFor..., unpack and iterate\n",
    "    if isinstance(teacher, BertModel) or type(teacher).__name__.startswith('BertFor'):\n",
    "        for teacher_part, student_part in zip(teacher.children(), student.children()):\n",
    "            distill_bert_weights(teacher_part, student_part)\n",
    "    # Else if the part is an encoder, copy one out of every layer\n",
    "    elif isinstance(teacher, BertEncoder):\n",
    "        teacher_encoding_layers = [layer for layer in next(teacher.children())] #12 layers\n",
    "        student_encoding_layers = [layer for layer in next(student.children())] #12 layers\n",
    "        for i in range(len(student_encoding_layers)):\n",
    "            student_encoding_layers[i].load_state_dict(teacher_encoding_layers[i].state_dict())\n",
    "    # Else the part is a head or something else, copy the state_dict\n",
    "    else:\n",
    "        student.load_state_dict(teacher.state_dict())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = distill_bert_weights(teacher=teacher_model, student=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher parameters : 109483778\n",
      "Student parameters : 109483778\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Teacher parameters :', count_parameters(teacher_model))\n",
    "print('Student parameters :', count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)/count_parameters(teacher_model) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def get_nb_trainable_parameters():\n",
    "    r\"\"\"\n",
    "    Returns the number of trainable parameters and number of all parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        num_params = param.numel()\n",
    "        # if using DS Zero 3 and the weights are initialized empty\n",
    "        if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
    "            num_params = param.ds_numel\n",
    "\n",
    "        # Due to the design of 4bit linear layers from bitsandbytes\n",
    "        # one needs to multiply the number of parameters by 2 to get\n",
    "        # the correct number of parameters\n",
    "        if param.__class__.__name__ == \"Params4bit\":\n",
    "            num_params = num_params * 2\n",
    "\n",
    "        all_param += num_params\n",
    "        if param.requires_grad:\n",
    "            trainable_params += num_params\n",
    "\n",
    "    return trainable_params, all_param\n",
    "\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params, all_param = get_nb_trainable_parameters()\n",
    "\n",
    "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 109,778,690 || trainable%: 0.2686423020715587\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Force CPU usage\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "# block_size = tokenizer.model_max_length\n",
    "\n",
    "# # Main data processing function that will concatenate all texts from our dataset and generate chunks of block_size.\n",
    "# def group_texts(examples):\n",
    "#     # Concatenate all texts.\n",
    "#     concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "#     total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "#     # We drop the small remainder, and if the total_length < block_size  we exclude this batch and return an empty dict.\n",
    "#     # We could add padding if the model supported it instead of this drop, you can customize this part to your needs.\n",
    "#     total_length = (total_length // block_size) * block_size\n",
    "#     # Split by chunks of max_len.\n",
    "#     result = {\n",
    "#         k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "#         for k, t in concatenated_examples.items()\n",
    "#     }\n",
    "#     result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "#     return result\n",
    "\n",
    "# tokenized_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "# tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_l\"ogits_for_metrics but we need to shift the labels\n",
    "    labels = labels[:, 1:].reshape(-1)\n",
    "    preds = preds[:, :-1].reshape(-1)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TrainingArguments, Trainer, default_data_collator\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"distilBERT-lora\",\n",
    "#     learning_rate=1e-3,\n",
    "#     per_device_train_batch_size=4,\n",
    "#     per_device_eval_batch_size=2,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     num_train_epochs=2,\n",
    "#     weight_decay=0.01,\n",
    "#     # load_best_model_at_end=True,\n",
    "#     fp16=True\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_datasets[\"train\"],\n",
    "#     eval_dataset=tokenized_datasets[\"test\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=default_data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# trainer.train()\n",
    "# trainer.save_model()\n",
    "# model.save_pretrained(\"distilBERT-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It has 40% less parameters than bert-base-uncased"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax\n",
    "\n",
    "$$\n",
    "P_i(\\mathbf{z}_i, T) = \\frac{\\exp(\\mathbf{z}_i / T)}{\\sum_{q=0}^k \\exp(\\mathbf{z}_q / T)}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowledge Distillation\n",
    "\n",
    "#### CE Loss\n",
    "$$\\mathcal{L}_\\text{CE} = -\\sum^N_{j=0}\\sum_{i=0}^k {y}_i^{(j)}\\log(P_i({v}_i^{(j)}, 1))$$\n",
    "\n",
    "#### KL Loss\n",
    "$$\\mathcal{L}_\\text{KD} = -\\sum^N_{j=0}\\sum_{i=0}^k P_i({z}_i^{(j)}, T) \\log (P_i({v}_i^{(j)}, T))$$\n",
    "\n",
    "#### Cosine Embedding Loss\n",
    "$$\\mathcal{L}_{\\text{cosine}}(x_1, x_2, y) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(1 - y_i \\cdot \\cos(\\theta_i)\\right)$$\n",
    "\n",
    "<!-- $$\\mathcal{L} = \\lambda \\mathcal{L}_\\text{KD} + (1-\\lambda)\\mathcal{L}_\\text{CE}$$\n",
    " -->\n",
    "\n",
    "#### Total Loss\n",
    "$$\\mathcal{L} = \\mathcal{L}_\\text{KD} + \\mathcal{L}_\\text{CE} + \\mathcal{L}_{\\text{cosine}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DistillKL(nn.Module):\n",
    "    \"\"\"\n",
    "    Distilling the Knowledge in a Neural Network\n",
    "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
    "    \"Hyperparameters\": temperature and alpha\n",
    "\n",
    "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
    "    and student expects the input tensor to be log probabilities! \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistillKL, self).__init__()\n",
    "\n",
    "    def forward(self, output_student, output_teacher, temperature=1):\n",
    "        '''\n",
    "        Note: the output_student and output_teacher are logits \n",
    "        '''\n",
    "        T = temperature #.cuda()\n",
    "        \n",
    "        KD_loss = nn.KLDivLoss(reduction='batchmean')(\n",
    "            F.log_softmax(output_student/T, dim=-1),\n",
    "            F.softmax(output_teacher/T, dim=-1)\n",
    "        ) * T * T\n",
    "        \n",
    "        return KD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_div = DistillKL()\n",
    "criterion_cos = nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "lr = 5e-5\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "teacher_model = teacher_model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 5\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import evaluate\n",
    "# # Get the metric function\n",
    "# if task_name is not None:\n",
    "#     metric = evaluate.load(\"glue\", task_name)\n",
    "# else:\n",
    "#     metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "# teacher_model.to(device)  # Move the teacher model as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5c1769100f4009850dc64900bdee1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 1: Train loss 0.2570:\n",
      "  - Loss_cls: 0.6930\n",
      "  - Loss_div: 0.0068\n",
      "  - Loss_cos: 0.0711\n",
      "Epoch at 1: Test Acc 0.7240\n",
      "Epoch at 2: Train loss 0.2512:\n",
      "  - Loss_cls: 0.6645\n",
      "  - Loss_div: 0.0098\n",
      "  - Loss_cos: 0.0795\n",
      "Epoch at 2: Test Acc 0.7920\n",
      "Epoch at 3: Train loss 0.2453:\n",
      "  - Loss_cls: 0.6292\n",
      "  - Loss_div: 0.0162\n",
      "  - Loss_cos: 0.0905\n",
      "Epoch at 3: Test Acc 0.8340\n",
      "Epoch at 4: Train loss 0.2403:\n",
      "  - Loss_cls: 0.5938\n",
      "  - Loss_div: 0.0255\n",
      "  - Loss_cos: 0.1016\n",
      "Epoch at 4: Test Acc 0.8480\n",
      "Epoch at 5: Train loss 0.2364:\n",
      "  - Loss_cls: 0.5817\n",
      "  - Loss_div: 0.0279\n",
      "  - Loss_cos: 0.0996\n",
      "Epoch at 5: Test Acc 0.8400\n",
      "Avg Metric 0.8076000000000001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "eval_metrics = 0\n",
    "\n",
    "# Lists to store losses for each epoch\n",
    "train_losses = []\n",
    "train_losses_cls = []\n",
    "train_losses_div = []\n",
    "train_losses_cos = []\n",
    "eval_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    teacher_model.eval()\n",
    "    train_loss = 0\n",
    "    train_loss_cls = 0\n",
    "    train_loss_div = 0\n",
    "    train_loss_cos = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        # compute student output\n",
    "        outputs = model(**batch) \n",
    "        # compute teacher output\n",
    "        with torch.no_grad():\n",
    "            output_teacher = teacher_model(**batch)\n",
    "\n",
    "        # assert size\n",
    "        assert outputs.logits.size() == output_teacher.logits.size()\n",
    "        \n",
    "        # cls loss \n",
    "        loss_cls  = outputs.loss\n",
    "        train_loss_cls += loss_cls.item()\n",
    "        # distillation loss\n",
    "        loss_div = criterion_div(outputs.logits, output_teacher.logits)\n",
    "        train_loss_div += loss_div.item()\n",
    "        # cosine loss\n",
    "        loss_cos = criterion_cos(output_teacher.logits, outputs.logits, torch.ones(output_teacher.logits.size()[0]).to(device))\n",
    "        train_loss_cos += loss_cos.item()\n",
    "        \n",
    "        # Average the loss and return it\n",
    "        loss = (loss_cls + loss_div + loss_cos) / 3\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # accelerator.backward(loss)\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    train_losses.append(train_loss / len(train_dataloader))\n",
    "    train_losses_cls.append(train_loss_cls / len(train_dataloader))\n",
    "    train_losses_div.append(train_loss_div / len(train_dataloader))\n",
    "    train_losses_cos.append(train_loss_cos / len(train_dataloader))\n",
    "\n",
    "    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n",
    "    print(f'  - Loss_cls: {train_loss_cls/len(train_dataloader):.4f}')\n",
    "    print(f'  - Loss_div: {train_loss_div/len(train_dataloader):.4f}')\n",
    "    print(f'  - Loss_cos: {train_loss_cos/len(train_dataloader):.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "        loss_cls = outputs.loss\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        eval_loss += loss_cls.item()\n",
    "        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "        metric.add_batch(\n",
    "            predictions=predictions, \n",
    "            references=batch[\"labels\"])\n",
    "        \n",
    "    eval_metric = metric.compute()\n",
    "    eval_metrics += eval_metric['accuracy'] \n",
    "    eval_losses.append(eval_loss / len(eval_dataloader))  # Save the evaluation loss for plotting\n",
    "    \n",
    "    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n",
    "    \n",
    "print('Avg Metric', eval_metrics/num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting\n",
    "epochs_list = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs_list, train_losses, label='Total Train Loss')\n",
    "plt.plot(epochs_list, train_losses_cls, label='Train Loss_cls')\n",
    "plt.plot(epochs_list, train_losses_div, label='Train Loss_div')\n",
    "plt.plot(epochs_list, train_losses_cos, label='Train Loss_cos')\n",
    "plt.plot(epochs_list, eval_losses, label='Validation Loss')\n",
    "\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix (Teacher Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354a220dfc4343a192d29dfa14e85c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 1: Train loss 0.2391:\n",
      "Epoch at 1: Test Acc 0.9500\n",
      "Epoch at 2: Train loss 0.0940:\n",
      "Epoch at 2: Test Acc 0.9420\n",
      "Epoch at 3: Train loss 0.0391:\n",
      "Epoch at 3: Test Acc 0.9380\n",
      "Epoch at 4: Train loss 0.0221:\n",
      "Epoch at 4: Test Acc 0.9500\n",
      "Epoch at 5: Train loss 0.0361:\n",
      "Epoch at 5: Test Acc 0.9380\n",
      "Avg Metric 0.9436\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "lr = 5e-5\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(params=teacher_model.parameters(), lr=lr)\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "eval_metrics = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    teacher_model.train()\n",
    "    train_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        output_teacher = teacher_model(**batch)\n",
    "        # cls loss \n",
    "        loss = output_teacher.loss\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # accelerator.backward(loss)\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n",
    "    \n",
    "    teacher_model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = teacher_model(**batch)\n",
    "    \n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "        metric.add_batch(\n",
    "            predictions=predictions, \n",
    "            references=batch[\"labels\"])\n",
    "        \n",
    "    eval_metric = metric.compute()\n",
    "    eval_metrics += eval_metric['accuracy'] \n",
    "    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n",
    "    \n",
    "print('Avg Metric', eval_metrics/num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
